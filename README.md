# Introduction to Artificial Intelligence

Interactive visualizations and implementations of fundamental AI algorithms for education and experimentation. All modules available as **desktop applications** and **browser-based demos** (no installation required!).

## ğŸŒŸ Features

- **Interactive Visualizations** - Watch algorithms work step-by-step
- **Browser & Desktop** - Run locally or access via web
- **Student-Friendly** - Comprehensive guides and tutorials
- **Configurable** - Adjust parameters with sliders and presets
- **Educational Focus** - Built for learning, not just demonstration

## ğŸš€ Quick Start

### Try in Your Browser (No Installation!)

Visit the live demos:
- **Search Algorithms**: https://chinwh2019.github.io/intro-ai/search/
- **MDP**: https://chinwh2019.github.io/intro-ai/mdp/
- **Reinforcement Learning**: https://chinwh2019.github.io/intro-ai/reinforcement_learning/

### Run on Your Computer

```bash
# Clone the repository
git clone https://github.com/chinwh2019/intro-ai.git
cd intro-ai

# Install dependencies
pip install -r requirements.txt

# Run any module
python scripts/run_search.py
python scripts/run_mdp.py
python scripts/run_rl.py
```

## ğŸ“š Documentation

- **[GitHub Wiki](https://github.com/chinwh2019/intro-ai/wiki)** - Comprehensive tutorials and theory
- **Module READMEs** - Quick reference for each module
- **Student Guides** - Step-by-step learning paths

## ğŸ“‚ Project Structure

```
intro-ai/
â”œâ”€â”€ modules/              # Desktop implementations
â”‚   â”œâ”€â”€ search/          # Search algorithms (BFS, DFS, UCS, A*, Greedy)
â”‚   â”œâ”€â”€ mdp/             # Markov Decision Processes
â”‚   â””â”€â”€ reinforcement_learning/  # Q-Learning with Snake
â”‚
â”œâ”€â”€ web/                 # Browser-compatible versions (Pygbag/WASM)
â”‚   â”œâ”€â”€ search/
â”‚   â”œâ”€â”€ mdp/
â”‚   â””â”€â”€ reinforcement_learning/
â”‚
â”œâ”€â”€ scripts/             # Runner scripts
â”‚   â”œâ”€â”€ run_search.py
â”‚   â”œâ”€â”€ run_mdp.py
â”‚   â””â”€â”€ run_rl.py
â”‚
â”œâ”€â”€ wiki/                # GitHub Wiki content
â”œâ”€â”€ legacy/              # Archived old implementations
â””â”€â”€ requirements.txt     # Dependencies
```

## ğŸ” Search Algorithms

Interactive maze solver with 5 search algorithms:

- **Breadth-First Search (BFS)** - Layer-by-layer exploration
- **Depth-First Search (DFS)** - Deep exploration with backtracking
- **Uniform Cost Search (UCS)** - Optimal for weighted graphs
- **A* Search** - Optimal + efficient with heuristics
- **Greedy Best-First** - Fast heuristic-guided search

**Features:**
- Real-time step-by-step visualization
- Interactive parameter controls (speed, heuristic weight, complexity)
- Performance metrics comparison
- Random maze generation
- Custom start/goal positioning

**Documentation:** [modules/search/README.md](modules/search/README.md) | [Student Guide](modules/search/STUDENT_GUIDE.md)

## ğŸ² Markov Decision Processes (MDPs)

Grid world environment with planning under uncertainty:

- **Value Iteration** - Compute optimal values and policies
- **Stochastic Transitions** - Model uncertainty (slippery grid)
- **Interactive Controls** - Adjust discount, noise, rewards
- **Visual Convergence** - Watch values propagate

**Features:**
- Real-time value function visualization
- Policy arrows showing optimal actions
- Q-value display for all state-action pairs
- Configurable discount factor and noise levels

**Documentation:** [modules/mdp/README.md](modules/mdp/README.md) | [Student Guide](modules/mdp/STUDENT_GUIDE.md)

## ğŸ Reinforcement Learning

Q-Learning agent learning to play Snake:

- **Q-Learning Algorithm** - Off-policy TD learning
- **Îµ-Greedy Exploration** - Balanced exploration/exploitation
- **Interactive Training** - Adjust hyperparameters in real-time
- **Training/Inference Modes** - Learn or watch trained agent
- **Model Persistence** - Save and load trained Q-tables (desktop)

**Features:**
- Live Q-value display showing agent's learning
- Training statistics and learning curves
- Preset configurations for different learning scenarios
- Parameter sliders (learning rate, epsilon, discount, speed)

**Documentation:** [modules/reinforcement_learning/README.md](modules/reinforcement_learning/README.md) | [Student Guide](modules/reinforcement_learning/STUDENT_GUIDE.md)

## ğŸ¤– Machine Learning

[Coming Soon]

## âœ¨ Generative AI

[Coming Soon]

## ğŸ’» Installation

### Prerequisites
- Python 3.8 or higher
- pip (Python package manager)

### Setup

```bash
# 1. Clone the repository
git clone https://github.com/chinwh2019/intro-ai.git
cd intro-ai

# 2. Install dependencies
pip install -r requirements.txt
```

**Dependencies:**
- `pygame` - Graphics and visualization
- `numpy` - Numerical operations (desktop only)
- `matplotlib` - Learning curves (desktop only, RL module)

## ğŸ® Usage

### Desktop Versions (Full Features)

```bash
# Search Algorithms
python scripts/run_search.py
# Press 1-5 to select algorithm, SPACE to pause, R to reset

# MDP
python scripts/run_mdp.py
# Press SPACE to start value iteration, P for policy, V for values

# Reinforcement Learning
python scripts/run_rl.py --preset turbo
# Press T to toggle training/inference, S to save model
```

### With Presets

```bash
# Fast learning
python scripts/run_rl.py --preset fast_learning

# Simple small maze
python scripts/run_search.py --preset simple

# Deterministic MDP (no noise)
python scripts/run_mdp.py --preset deterministic
```

### Browser Versions (No Installation)

Visit the live demos:
- Search: https://chinwh2019.github.io/intro-ai/search/
- MDP: https://chinwh2019.github.io/intro-ai/mdp/
- RL: https://chinwh2019.github.io/intro-ai/reinforcement_learning/

**Note:** Web versions don't support model save/load or matplotlib visualizations.

## ğŸ“– Learning Resources

### For Students

1. **[GitHub Wiki](https://github.com/chinwh2019/intro-ai/wiki)** - Comprehensive theory and tutorials
   - Algorithm explanations
   - Step-by-step guides
   - Exercises and challenges
   - Troubleshooting

2. **Module Documentation**
   - [Search README](modules/search/README.md) + [Student Guide](modules/search/STUDENT_GUIDE.md)
   - [MDP README](modules/mdp/README.md) + [Student Guide](modules/mdp/STUDENT_GUIDE.md)
   - [RL README](modules/reinforcement_learning/README.md) + [Student Guide](modules/reinforcement_learning/STUDENT_GUIDE.md)

3. **Interactive Controls**
   - All modules have parameter sliders
   - Adjust settings in real-time
   - Experiment without coding

### For Instructors

- Modular architecture for easy customization
- Preset configurations for classroom demos
- Web deployment for zero-setup student access
- Comprehensive wiki for reducing repetitive questions

## ğŸ¯ Key Features by Module

### Search Algorithms
- âœ… 5 algorithms (BFS, DFS, UCS, A*, Greedy)
- âœ… Interactive parameter panel (speed, heuristic, complexity)
- âœ… Step-by-step execution
- âœ… Random start/goal mode
- âœ… Performance metrics

### MDP
- âœ… Value iteration visualization
- âœ… Policy display with arrows
- âœ… Q-value display for all actions
- âœ… Stochastic transitions (configurable noise)
- âœ… Real-time convergence tracking

### Reinforcement Learning
- âœ… Q-Learning with Îµ-greedy
- âœ… Live Q-value display
- âœ… Training/inference modes
- âœ… Model save/load (desktop)
- âœ… Interactive hyperparameter tuning
- âœ… Learning curve visualization (desktop)

## ğŸ› ï¸ Configuration

All modules support multiple configuration methods:

**Method 1: Interactive sliders** (easiest - while running)
- Adjust parameters via UI
- Click Apply button
- Changes take effect immediately

**Method 2: Presets** (command line)
```bash
python scripts/run_rl.py --preset turbo
python scripts/run_search.py --preset simple
```

**Method 3: Edit config.py** (programmatic)
```python
from modules.search.config import config
config.MAZE_WIDTH = 50
config.ANIMATION_SPEED = 2.0
```

## ğŸŒ Web Deployment

All modules deployed to GitHub Pages using Pygbag (Python â†’ WebAssembly):

- **Automatic deployment** via GitHub Actions
- **No server costs** - static file hosting
- **Instant updates** - push to main, auto-deploys
- **Cross-platform** - works on any modern browser

**Architecture:**
- Desktop: Full Python with NumPy, Matplotlib
- Web: Pure Python (NumPy-free), async/await compatible

## ğŸ¤ Contributing

Contributions welcome! Areas where help is appreciated:

- New algorithms (bidirectional search, IDA*, SARSA, etc.)
- New environments (different games, puzzles)
- Additional exercises and tutorials
- Wiki page improvements
- Bug fixes and optimizations

**Process:**
1. Fork the repository
2. Create feature branch: `git checkout -b feature-name`
3. Make changes and test
4. Commit: `git commit -m 'Add feature'`
5. Push: `git push origin feature-name`
6. Create Pull Request

## ğŸ“ For Educators

This repository is designed for teaching:

- **Modular design** - Use one or all modules
- **Multiple access modes** - Desktop, web, or both
- **Preset configurations** - Quick demos without coding
- **Comprehensive docs** - Wiki, READMEs, student guides
- **Active learning** - Students experiment, not just watch

**Classroom tested** - Used in university AI courses.

## ğŸ”— Links

- **Live Demos**: https://chinwh2019.github.io/intro-ai/
- **Wiki**: https://github.com/chinwh2019/intro-ai/wiki
- **Issues**: https://github.com/chinwh2019/intro-ai/issues

## ğŸ“ License
